"""
GitHub Research Module –¥–ª—è –ø–æ–∏—Å–∫–∞ –ª—É—á—à–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ UI –∞–Ω–∞–ª–∏–∑–∞
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å GitHub MCP Server –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ä–µ—à–µ–Ω–∏–π
"""

import requests
import json
import os
from typing import List, Dict, Optional
from datetime import datetime
import time

try:
    from github_config import GITHUB_TOKEN, SEARCH_CONFIG, SEARCH_QUERIES
except ImportError:
    GITHUB_TOKEN = None
    SEARCH_CONFIG = {"max_results_per_query": 10, "min_stars": 3, "search_delay": 1}
    SEARCH_QUERIES = [
        "UI element detection computer vision language:python stars:>10",
        "GUI automation element detection screenshot stars:>5",
        "web scraping element detection python stars:>20"
    ]

class GitHubUIResearcher:
    """–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è UI –∞–Ω–∞–ª–∏–∑–∞"""
    def __init__(self, token: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è
        
        Args:
            token: GitHub Personal Access Token (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        self.token = token or GITHUB_TOKEN or os.getenv('GITHUB_TOKEN')
        self.headers = {
            'Accept': 'application/vnd.github.v3+json',
            'User-Agent': 'UI-Agent-Research-Tool'
        }
        if self.token and self.token != "your_github_token_here":
            self.headers['Authorization'] = f'token {self.token}'
            print("‚úÖ GitHub —Ç–æ–∫–µ–Ω –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        else:
            print("‚ö†Ô∏è GitHub —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø.")
        
        self.base_url = 'https://api.github.com'
        self.search_history = []
        self.config = SEARCH_CONFIG
        
    def search_ui_analysis_repositories(self, max_results: int = 50) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ —Å –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏ UI –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            max_results: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
        """
        print("üîç –ù–∞—á–∏–Ω–∞—é –ø–æ–∏—Å–∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è UI –∞–Ω–∞–ª–∏–∑–∞...")
          # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        search_queries = SEARCH_QUERIES
        
        all_repos = []
        
        for i, query in enumerate(search_queries, 1):
            print(f"üìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å {i}/{len(search_queries)}: {query[:50]}...")
            try:
                repos = self._search_repositories(query, per_page=self.config.get('max_results_per_query', 10))
                all_repos.extend(repos)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                time.sleep(self.config.get('search_delay', 1))
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ '{query}': {e}")
                continue
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º
        unique_repos = self._remove_duplicates(all_repos)
        filtered_repos = self._filter_relevant_repos(unique_repos)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        final_repos = self._rank_repositories(filtered_repos)[:max_results]
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(final_repos)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤")
        return final_repos
    
    def _search_repositories(self, query: str, per_page: int = 10) -> List[Dict]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ GitHub API"""
        url = f"{self.base_url}/search/repositories"
        params = {
            'q': query,
            'sort': 'stars',
            'order': 'desc',
            'per_page': per_page
        }
        
        response = requests.get(url, headers=self.headers, params=params)
        
        if response.status_code == 200:
            data = response.json()
            return data.get('items', [])
        elif response.status_code == 403:
            print("‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ GitHub API. –û–∂–∏–¥–∞–Ω–∏–µ...")
            time.sleep(60)  # –ñ–¥–µ–º –º–∏–Ω—É—Ç—É
            return []
        else:
            response.raise_for_status()
    
    def _remove_duplicates(self, repos: List[Dict]) -> List[Dict]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ ID —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
        seen_ids = set()
        unique_repos = []
        
        for repo in repos:
            if repo['id'] not in seen_ids:
                seen_ids.add(repo['id'])
                unique_repos.append(repo)
        
        return unique_repos
    
    def _filter_relevant_repos(self, repos: List[Dict]) -> List[Dict]:
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤"""
        relevant_repos = []
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        ui_keywords = [
            'ui', 'gui', 'interface', 'element', 'detection', 'automation',
            'screenshot', 'ocr', 'vision', 'computer', 'machine', 'learning',
            'selenium', 'playwright', 'opencv', 'testing', 'scraping',
            'annotation', 'bounding', 'box', 'recognition', 'analysis'
        ]
        
        for repo in repos:
            description = (repo.get('description') or '').lower()
            name = repo.get('name', '').lower()
            topics = [topic.lower() for topic in repo.get('topics', [])]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            text_to_check = f"{description} {name} {' '.join(topics)}"
            keyword_count = sum(1 for keyword in ui_keywords if keyword in text_to_check)
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏ –∑–≤–µ–∑–¥
            if (keyword_count >= 2 and 
                repo.get('stargazers_count', 0) >= 3 and
                not repo.get('archived', False)):
                
                relevant_repos.append({
                    'id': repo['id'],
                    'name': repo['name'],
                    'full_name': repo['full_name'],
                    'description': repo.get('description', ''),
                    'html_url': repo['html_url'],
                    'stars': repo['stargazers_count'],
                    'forks': repo['forks_count'],
                    'language': repo.get('language', 'Unknown'),
                    'topics': repo.get('topics', []),
                    'updated_at': repo['updated_at'],
                    'created_at': repo['created_at'],
                    'relevance_score': keyword_count,
                    'size': repo.get('size', 0)
                })
        
        return relevant_repos
    
    def _rank_repositories(self, repos: List[Dict]) -> List[Dict]:
        """–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏"""
        def calculate_score(repo):
            """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
            stars_score = min(repo['stars'] / 100, 10)  # –ú–∞–∫—Å–∏–º—É–º 10 –±–∞–ª–ª–æ–≤ –∑–∞ –∑–≤–µ–∑–¥—ã
            relevance_score = repo['relevance_score'] * 2  # 2 –±–∞–ª–ª–∞ –∑–∞ –∫–∞–∂–¥–æ–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
            language_score = 3 if repo['language'] == 'Python' else 1  # –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ Python
            freshness_score = self._calculate_freshness_score(repo['updated_at'])
            
            return stars_score + relevance_score + language_score + freshness_score
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–π —Ä–µ–π—Ç–∏–Ω–≥
        for repo in repos:
            repo['total_score'] = calculate_score(repo)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–π—Ç–∏–Ω–≥—É
        return sorted(repos, key=lambda x: x['total_score'], reverse=True)
    
    def _calculate_freshness_score(self, updated_at: str) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –±–∞–ª–ª–æ–≤ –∑–∞ —Å–≤–µ–∂–µ—Å—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
        try:
            updated_date = datetime.fromisoformat(updated_at.replace('Z', '+00:00'))
            now = datetime.now(updated_date.tzinfo)
            days_ago = (now - updated_date).days
            
            if days_ago < 30:
                return 3
            elif days_ago < 180:
                return 2
            elif days_ago < 365:
                return 1
            else:
                return 0
        except:
            return 0
    
    def get_repository_details(self, repo_name: str) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏"""
        url = f"{self.base_url}/repos/{repo_name}"
        
        response = requests.get(url, headers=self.headers)
        
        if response.status_code == 200:
            return response.json()
        else:
            response.raise_for_status()
    
    def get_repository_readme(self, repo_name: str) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ README —Ñ–∞–π–ª–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
        url = f"{self.base_url}/repos/{repo_name}/readme"
        
        response = requests.get(url, headers=self.headers)
        
        if response.status_code == 200:
            content = response.json()
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64 –∫–æ–Ω—Ç–µ–Ω—Ç
            import base64
            readme_content = base64.b64decode(content['content']).decode('utf-8')
            return readme_content
        else:
            return None
    
    def analyze_repository_code(self, repo_name: str, file_extensions: List[str] = None) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–æ–¥–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
        if file_extensions is None:
            file_extensions = ['.py', '.js', '.cpp', '.java']
        
        url = f"{self.base_url}/repos/{repo_name}/contents"
        
        try:
            response = requests.get(url, headers=self.headers)
            
            if response.status_code == 200:
                contents = response.json()
                
                analysis = {
                    'total_files': 0,
                    'code_files': 0,
                    'directories': 0,
                    'file_types': {},
                    'key_files': []
                }
                
                for item in contents:
                    if item['type'] == 'file':
                        analysis['total_files'] += 1
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
                        name = item['name'].lower()
                        for ext in file_extensions:
                            if name.endswith(ext):
                                analysis['code_files'] += 1
                                analysis['file_types'][ext] = analysis['file_types'].get(ext, 0) + 1
                                break
                        
                        # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã
                        if any(keyword in name for keyword in 
                               ['detect', 'ui', 'element', 'vision', 'ocr', 'analysis']):
                            analysis['key_files'].append(item['name'])
                    
                    elif item['type'] == 'dir':
                        analysis['directories'] += 1
                
                return analysis
            
            else:
                return {'error': f'Failed to access repository: {response.status_code}'}
                
        except Exception as e:
            return {'error': str(e)}
    
    def save_research_results(self, repos: List[Dict], filename: str = None) -> str:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"github_ui_research_{timestamp}.json"
        
        research_data = {
            'timestamp': datetime.now().isoformat(),
            'total_repositories': len(repos),
            'repositories': repos,
            'search_summary': {
                'top_languages': self._get_language_stats(repos),
                'average_stars': sum(r['stars'] for r in repos) / len(repos) if repos else 0,
                'most_recent': max(r['updated_at'] for r in repos) if repos else None
            }
        }
        
        filepath = os.path.join('learning_data', filename)
        os.makedirs('learning_data', exist_ok=True)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(research_data, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filepath}")
        return filepath
    
    def _get_language_stats(self, repos: List[Dict]) -> Dict[str, int]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —è–∑—ã–∫–∞–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è"""
        languages = {}
        for repo in repos:
            lang = repo.get('language', 'Unknown')
            languages[lang] = languages.get(lang, 0) + 1
        
        return dict(sorted(languages.items(), key=lambda x: x[1], reverse=True))
    
    def print_research_summary(self, repos: List[Dict]):
        """–í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""
        if not repos:
            print("‚ùå –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
        
        print(f"\nüìä –°–í–û–î–ö–ê –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø GitHub")
        print("=" * 50)
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {len(repos)}")
        print(f"‚≠ê –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥: {sum(r['stars'] for r in repos) / len(repos):.1f} –∑–≤–µ–∑–¥")
        
        # –¢–æ–ø —è–∑—ã–∫–æ–≤
        languages = self._get_language_stats(repos)
        print(f"\nüíª –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —è–∑—ã–∫–∏:")
        for lang, count in list(languages.items())[:5]:
            print(f"   {lang}: {count} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤")
        
        # –¢–æ–ø —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
        print(f"\nüèÜ –¢–û–ü-10 –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–• –†–ï–ü–û–ó–ò–¢–û–†–ò–ï–í:")
        print("-" * 50)
        
        for i, repo in enumerate(repos[:10], 1):
            print(f"{i:2d}. ‚≠ê{repo['stars']:4d} | {repo['name']}")
            print(f"     üìù {repo['description'][:80]}...")
            print(f"     üîó {repo['html_url']}")
            print(f"     üíª {repo['language']} | üîÑ {repo['updated_at'][:10]}")
            print()

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –ó–∞–ø—É—Å–∫ GitHub –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è UI –∞–Ω–∞–ª–∏–∑–∞...")
    
    # –°–æ–∑–¥–∞–µ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è
    researcher = GitHubUIResearcher()
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
    repos = researcher.search_ui_analysis_repositories(max_results=30)
    
    # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
    researcher.print_research_summary(repos)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    researcher.save_research_results(repos)
    
    print("\n‚úÖ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

if __name__ == "__main__":
    main()

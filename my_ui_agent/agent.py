import os
import json
import datetime
from pathlib import Path
from google.cloud import vision
from PIL import Image, ImageDraw, ImageFont
import numpy as np
from collections import Counter
import colorsys
from github_researcher import GitHubUIResearcher

# --- Mobile Gaming UI Taxonomy ---
MOBILE_GAMING_UI_TAXONOMY = {
    'interactive': [
        'button', 'action_button', 'menu_button', 'close_button', 'back_button',
        'joystick', 'virtual_joystick', 'directional_pad', 'touch_zone',
        'slider', 'toggle', 'checkbox', 'radio_button', 'dropdown', 
        'input_field', 'search_box', 'skill_button', 'attack_button'
    ],
    
    'navigational': [
        'menu', 'main_menu', 'pause_menu', 'settings_menu', 'inventory_menu',
        'tab', 'menu_tab', 'navigation_bar', 'breadcrumb', 'pagination', 
        'scroll_bar', 'home_button', 'minimap', 'compass'
    ],
    
    'informational': [
        'text_label', 'title_text', 'description_text', 'instruction_text',
        'icon', 'weapon_icon', 'item_icon', 'skill_icon', 'currency_icon',
        'image', 'logo', 'avatar', 'progress_indicator', 'health_bar', 
        'mana_bar', 'experience_bar', 'status_bar', 'notification', 
        'score_counter', 'coin_counter', 'level_indicator'
    ],
    
    'structural': [
        'panel', 'background_panel', 'card', 'list_item', 'grid_item', 
        'modal', 'popup', 'overlay', 'container', 'divider', 'frame',
        'border_frame', 'inventory_slot', 'chat_window'
    ],
    
    'gaming_specific': [
        'hud_element', 'minimap', 'health_bar', 'mana_bar', 'stamina_bar',
        'inventory_slot', 'skill_button', 'achievement_badge', 
        'leaderboard_entry', 'chat_bubble', 'quest_marker', 
        'upgrade_button', 'shop_item', 'daily_deal', 'special_offer'
    ]
}

# –°–æ–∑–¥–∞–µ–º –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ç–µ–≥–æ–≤ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
ALL_UI_TAGS = []
for category, tags in MOBILE_GAMING_UI_TAXONOMY.items():
    ALL_UI_TAGS.extend(tags)

# --- UI Analysis Agent Class ---
class UIAnalysisAgent:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ UI —ç–ª–µ–º–µ–Ω—Ç–æ–≤"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞"""
        self.client = None
        self._init_vision_client()
        
    def _init_vision_client(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Vision API –∫–ª–∏–µ–Ω—Ç–∞"""
        try:
            self.client = vision.ImageAnnotatorClient()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Vision API: {e}")
            self.client = None
    
    def analyze_image(self, image_path):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        if not self.client:
            raise Exception("Vision API –∫–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        try:
            # –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Vision API
            objects, texts = self._analyze_with_vision_api(image_path)
            
            # –ê–Ω–∞–ª–∏–∑ UI —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            ui_elements = self._analyze_ui_elements(image_path)
            
            # –ê–Ω–∞–ª–∏–∑ —Ü–≤–µ—Ç–æ–≤
            colors = self._analyze_colors(image_path)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = {
                'objects': self._format_objects(objects),
                'texts': self._format_texts(texts),
                'ui_elements': ui_elements,
                'colors': colors,
                'statistics': {
                    'objects_count': len(objects) if objects else 0,
                    'texts_count': len(texts) - 1 if texts else 0,
                    'ui_elements_count': len(ui_elements)
                }
            }
            
            return result
            
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
    
    def _analyze_with_vision_api(self, image_path):
        """–ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Google Vision API"""
        with open(image_path, "rb") as image_file:
            content = image_file.read()
            
        gcp_image = vision.Image(content=content)
        
        features = [
            {"type_": vision.Feature.Type.OBJECT_LOCALIZATION},
            {"type_": vision.Feature.Type.TEXT_DETECTION},
        ]
        
        response = self.client.annotate_image({"image": gcp_image, "features": features})
        
        if response.error.message:
            raise Exception(f"Vision API –æ—à–∏–±–∫–∞: {response.error.message}")
        
        return response.localized_object_annotations, response.text_annotations
    
    def _analyze_ui_elements(self, image_path):
        """–ê–Ω–∞–ª–∏–∑ UI —ç–ª–µ–º–µ–Ω—Ç–æ–≤"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞
        try:
            colors = analyze_colors_simple(image_path)
            rectangular_regions = find_rectangular_regions(image_path)
            
            ui_elements = []
            for i, region in enumerate(rectangular_regions):
                ui_element = {
                    'id': f'ui_{i}',
                    'type': 'rectangular_region',
                    'bounding_poly': {
                        'vertices': [
                            {'x': region[0], 'y': region[1]},
                            {'x': region[2], 'y': region[1]},
                            {'x': region[2], 'y': region[3]},
                            {'x': region[0], 'y': region[3]}
                        ]
                    },
                    'confidence': 0.7,
                    'predicted_type': self._classify_ui_element(region)
                }
                ui_elements.append(ui_element)
            
            return ui_elements
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ UI —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {e}")
            return []
    
    def _analyze_colors(self, image_path):
        """–ê–Ω–∞–ª–∏–∑ —Ü–≤–µ—Ç–æ–≤–æ–π —Å—Ö–µ–º—ã"""
        try:
            return analyze_colors_simple(image_path)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ü–≤–µ—Ç–æ–≤: {e}")
            return []
    
    def _classify_ui_element(self, region):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è UI —ç–ª–µ–º–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–∞ –∏ —Ñ–æ—Ä–º—ã"""
        width = region[2] - region[0]
        height = region[3] - region[1]
        aspect_ratio = width / height if height > 0 else 1
        
        # –ü—Ä–æ—Å—Ç–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–∞
        if aspect_ratio > 3:
            return 'navigation_bar'
        elif aspect_ratio < 0.5:
            return 'button'
        elif width > 200 and height > 100:
            return 'panel'
        else:
            return 'unknown'
    
    def _format_objects(self, objects):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ Vision API"""
        if not objects:
            return []
        
        formatted = []
        for obj in objects:
            formatted.append({
                'name': obj.name,
                'confidence': obj.score,
                'bounding_poly': {
                    'vertices': [
                        {'x': vertex.x, 'y': vertex.y} 
                        for vertex in obj.bounding_poly.normalized_vertices
                    ]
                }
            })
        return formatted
    
    def _format_texts(self, texts):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ Vision API"""
        if not texts:
            return []
        
        formatted = []
        for text in texts:
            formatted.append({
                'description': text.description,
                'bounding_poly': {
                    'vertices': [
                        {'x': vertex.x, 'y': vertex.y} 
                        for vertex in text.bounding_poly.vertices
                    ]
                }
            })
        return formatted

# --- Dataset Building Classes ---
class UIElementAnnotation:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ UI —ç–ª–µ–º–µ–Ω—Ç–∞"""
    def __init__(self, bbox, predicted_type="unknown", actual_type=None, 
                 confidence=0.0, text="", context=""):
        self.bbox = bbox  # [x1, y1, x2, y2]
        self.predicted_type = predicted_type
        self.actual_type = actual_type
        self.confidence = confidence
        self.text = text
        self.context = context
        self.user_verified = actual_type is not None
    
    def to_dict(self):
        return {
            'bbox': self.bbox,
            'predicted_type': self.predicted_type,
            'actual_type': self.actual_type,
            'confidence': self.confidence,
            'text': self.text,
            'context': self.context,
            'user_verified': self.user_verified
        }

class DatasetBuilder:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    def __init__(self, output_dir="training_dataset"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.annotations_file = self.output_dir / "annotations.json"
        self.annotations = self.load_existing_annotations()
    
    def load_existing_annotations(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏"""
        if self.annotations_file.exists():
            with open(self.annotations_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []
    
    def save_annotations(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –≤ JSON —Ñ–∞–π–ª"""
        with open(self.annotations_file, 'w', encoding='utf-8') as f:
            json.dump(self.annotations, f, ensure_ascii=False, indent=2)
    
    def add_annotation(self, image_path, elements, metadata=None):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é –≤ –¥–∞—Ç–∞—Å–µ—Ç"""
        annotation = {
            'id': len(self.annotations),
            'image_path': str(image_path),
            'timestamp': datetime.datetime.now().isoformat(),
            'elements': [elem.to_dict() for elem in elements],
            'metadata': metadata or {}
        }
        self.annotations.append(annotation)
        self.save_annotations()
        return annotation['id']

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–º–æ–∂–Ω–æ –≤—ã–Ω–µ—Å—Ç–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è) ---
# –ï—Å–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è GOOGLE_APPLICATION_CREDENTIALS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ,
# –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –∫ –∫–ª—é—á—É –∑–¥–µ—Å—å (–º–µ–Ω–µ–µ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ):
# os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "C:\\–ø—É—Ç—å\\–∫\\–≤–∞—à–µ–º—É\\—Å–∫–∞—á–∞–Ω–Ω–æ–º—É-–∫–ª—é—á—É.json"

# --- –§—É–Ω–∫—Ü–∏–∏ –∞–≥–µ–Ω—Ç–∞ ---

def get_image_from_user():
    """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é."""
    while True:
        image_path = input("–í–≤–µ–¥–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: ").strip()
        if os.path.exists(image_path):
            try:
                # –ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                Image.open(image_path)
                return image_path
            except Exception as e:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª –∫–∞–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {e}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.")
        else:
            print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {image_path}. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")

def analyze_image_with_vision_ai(image_path):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ Google Cloud Vision API –∏ –ø–æ–ª—É—á–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."""
    try:
        client = vision.ImageAnnotatorClient()
        print("–û—Ç–ø—Ä–∞–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Google Cloud Vision API...")

        with open(image_path, "rb") as image_file:
            content = image_file.read()
        gcp_image = vision.Image(content=content)

        features = [
            {"type_": vision.Feature.Type.OBJECT_LOCALIZATION},
            {"type_": vision.Feature.Type.TEXT_DETECTION},
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥—Ä—É–≥–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, LABEL_DETECTION
        ]
        
        response = client.annotate_image({"image": gcp_image, "features": features})
        # response = client.batch_annotate_images(requests=[{"image": gcp_image, "features": features}]) # –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è annotate_image –ø—Ä–æ—â–µ

        if response.error.message:
            raise Exception(
                f"–û—à–∏–±–∫–∞ Vision API: {response.error.message}\n"
                "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ API –≤–∫–ª—é—á–µ–Ω –∏ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ."
            )

        localized_objects = response.localized_object_annotations
        text_annotations = response.text_annotations # –ü–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç - –≤–µ—Å—å —Ç–µ–∫—Å—Ç, –æ—Å—Ç–∞–ª—å–Ω—ã–µ - –±–ª–æ–∫–∏/—Å–ª–æ–≤–∞

        print("\n" + "="*50)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê GOOGLE VISION API")
        print("="*50)
        
        # –ê–Ω–∞–ª–∏–∑ –æ–±—ä–µ–∫—Ç–æ–≤
        print(f"üì¶ –û–ë–™–ï–ö–¢–´: {len(localized_objects)}")
        if localized_objects:
            for i, obj in enumerate(localized_objects, 1):
                print(f"   {i}. {obj.name} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {obj.score:.1%})")
        else:
            print("   –û–±—ä–µ–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞
        text_blocks = len(text_annotations) - 1 if text_annotations else 0
        print(f"\nüìù –¢–ï–ö–°–¢: {text_blocks} –±–ª–æ–∫–æ–≤")
        if text_annotations and len(text_annotations) > 1:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
            print("   –ù–∞–π–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (–ø–µ—Ä–≤—ã–µ 5 –±–ª–æ–∫–æ–≤):")
            for i, text in enumerate(text_annotations[1:6], 1):
                preview = text.description.replace('\n', ' ').strip()[:30]
                if len(text.description) > 30:
                    preview += "..."
                print(f"   {i}. \"{preview}\"")
            if text_blocks > 5:
                print(f"   ... –∏ –µ—â–µ {text_blocks - 5} –±–ª–æ–∫–æ–≤")
        else:
            print("   –¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        print("="*50)
            
        return localized_objects, text_annotations

    except Exception as e:
        print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–∏ —Å Google Cloud Vision API: {e}")
        return None, None

def draw_annotations(image_path, objects, texts, output_path="annotated_output.png", ui_analysis=None):
    """–°–æ–∑–¥–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç—å—é."""
    try:
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        pil_image = Image.open(image_path).convert("RGB")
        draw = ImageDraw.Draw(pil_image)
        img_width, img_height = pil_image.size
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —à—Ä–∏—Ñ—Ç–æ–≤ —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤
        try:
            title_font = ImageFont.truetype("arial.ttf", max(20, img_width // 50))
            label_font = ImageFont.truetype("arial.ttf", max(14, img_width // 80))
            small_font = ImageFont.truetype("arial.ttf", max(12, img_width // 100))
        except IOError:
            title_font = ImageFont.load_default()
            label_font = ImageFont.load_default()
            small_font = ImageFont.load_default()

        # –°–æ–∑–¥–∞–µ–º –ª–µ–≥–µ–Ω–¥—É –≤ –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        legend_height = 100
        legend_img = Image.new('RGB', (img_width, legend_height), color='white')
        legend_draw = ImageDraw.Draw(legend_img)
        
        # –†–∏—Å—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ª–µ–≥–µ–Ω–¥—ã
        legend_draw.text((10, 10), "–ù–ê–ô–î–ï–ù–ù–´–ï –≠–õ–ï–ú–ï–ù–¢–´ UI:", fill='black', font=title_font)
          # –î–æ–±–∞–≤–ª—è–µ–º —Ü–≤–µ—Ç–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        legend_y = 40
        if objects:
            legend_draw.rectangle([10, legend_y, 30, legend_y + 15], fill='blue', outline='black')
            legend_draw.text((35, legend_y), f"–û–±—ä–µ–∫—Ç—ã ({len(objects)})", fill='black', font=label_font)
        
        if texts and len(texts) > 1:
            text_count = len(texts) - 1
            legend_draw.rectangle([200, legend_y, 220, legend_y + 15], fill='red', outline='black')
            legend_draw.text((225, legend_y), f"–¢–µ–∫—Å—Ç ({text_count} –±–ª–æ–∫–æ–≤)", fill='black', font=label_font)
        
        # –î–æ–±–∞–≤–ª—è–µ–º UI —ç–ª–µ–º–µ–Ω—Ç—ã –≤ –ª–µ–≥–µ–Ω–¥—É
        if ui_analysis and ui_analysis.get("ui_elements"):
            ui_count = len(ui_analysis["ui_elements"])
            legend_draw.rectangle([400, legend_y, 420, legend_y + 15], fill='green', outline='black')
            legend_draw.text((425, legend_y), f"UI —ç–ª–µ–º–µ–Ω—Ç—ã ({ui_count})", fill='black', font=label_font)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ª–µ–≥–µ–Ω–¥—É —Å –æ—Å–Ω–æ–≤–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
        final_img = Image.new('RGB', (img_width, img_height + legend_height))
        final_img.paste(legend_img, (0, 0))
        final_img.paste(pil_image, (0, legend_height))
        
        # –†–∏—Å—É–µ–º –Ω–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ (—Å–º–µ—â–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–∞ –≤—ã—Å–æ—Ç—É –ª–µ–≥–µ–Ω–¥—ã)
        final_draw = ImageDraw.Draw(final_img)

        # –†–∏—Å—É–µ–º —Ä–∞–º–∫–∏ –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Å—Ç–∏–ª–µ–º
        for i, obj in enumerate(objects):
            # –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
            vertices = obj.bounding_poly.normalized_vertices
            box = [
                vertices[0].x * img_width, 
                vertices[0].y * img_height + legend_height,  # –°–º–µ—â–µ–Ω–∏–µ –Ω–∞ –ª–µ–≥–µ–Ω–¥—É
                vertices[2].x * img_width, 
                vertices[2].y * img_height + legend_height
            ]
            
            # –†–∏—Å—É–µ–º –ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—É—é —Ä–∞–º–∫—É
            box_color = 'blue'
            final_draw.rectangle(box, outline=box_color, width=4)
            
            # –†–∏—Å—É–µ–º —Ñ–æ–Ω –¥–ª—è –ø–æ–¥–ø–∏—Å–∏
            label = f"#{i+1}: {obj.name}"
            confidence = f"{obj.score:.0%}"
            
            # –ü–æ–∑–∏—Ü–∏—è –ø–æ–¥–ø–∏—Å–∏
            label_x = box[0] + 5
            label_y = box[1] - 35 if box[1] > legend_height + 35 else box[3] + 5
            
            # –†–∏—Å—É–µ–º –ø–æ–¥–ª–æ–∂–∫—É –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            text_bbox = final_draw.textbbox((label_x, label_y), label, font=label_font)
            final_draw.rectangle([text_bbox[0]-3, text_bbox[1]-2, text_bbox[2]+3, text_bbox[3]+2], 
                                fill='white', outline=box_color, width=2)
            
            # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç –ø–æ–¥–ø–∏—Å–∏
            final_draw.text((label_x, label_y), label, fill=box_color, font=label_font)
            final_draw.text((label_x, label_y + 20), confidence, fill=box_color, font=small_font)

        # –†–∏—Å—É–µ–º —Ä–∞–º–∫–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Å—Ç–∏–ª–µ–º
        if texts and len(texts) > 1:
            for i, text_block in enumerate(texts[1:]):
                vertices = text_block.bounding_poly.vertices
                x_coords = [v.x for v in vertices]
                y_coords = [v.y + legend_height for v in vertices]  # –°–º–µ—â–µ–Ω–∏–µ –Ω–∞ –ª–µ–≥–µ–Ω–¥—É
                box = [min(x_coords), min(y_coords), max(x_coords), max(y_coords)]
                
                # –†–∏—Å—É–µ–º —Ä–∞–º–∫—É –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                box_color = 'red'
                final_draw.rectangle(box, outline=box_color, width=3)
                
                # –ì–æ—Ç–æ–≤–∏–º –ø–æ–¥–ø–∏—Å—å
                text_content = text_block.description.replace('\n', ' ').strip()
                if len(text_content) > 20:
                    text_content = text_content[:17] + "..."
                
                label = f"T{i+1}: {text_content}"
                
                # –ü–æ–∑–∏—Ü–∏—è –ø–æ–¥–ø–∏—Å–∏
                label_x = box[0] + 3
                label_y = box[1] - 25 if box[1] > legend_height + 25 else box[3] + 3
                
                # –†–∏—Å—É–µ–º –ø–æ–¥–ª–æ–∂–∫—É –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                text_bbox = final_draw.textbbox((label_x, label_y), label, font=small_font)
                final_draw.rectangle([text_bbox[0]-2, text_bbox[1]-1, text_bbox[2]+2, text_bbox[3]+1], 
                                    fill='white', outline=box_color, width=1)
                  # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç –ø–æ–¥–ø–∏—Å–∏
                final_draw.text((label_x, label_y), label, fill=box_color, font=small_font)
        
        # –†–∏—Å—É–µ–º UI —ç–ª–µ–º–µ–Ω—Ç—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if ui_analysis and ui_analysis.get("ui_elements"):
            ui_elements = ui_analysis["ui_elements"]
            for i, element in enumerate(ui_elements):
                bounds = element.get("bounds", [0, 0, 0, 0])
                
                # –°–º–µ—â–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–∞ –≤—ã—Å–æ—Ç—É –ª–µ–≥–µ–Ω–¥—ã
                ui_box = [
                    bounds[0], 
                    bounds[1] + legend_height,
                    bounds[2], 
                    bounds[3] + legend_height
                ]
                
                # –†–∏—Å—É–µ–º —Ä–∞–º–∫—É UI —ç–ª–µ–º–µ–Ω—Ç–∞ (–∑–µ–ª–µ–Ω—ã–π —Ü–≤–µ—Ç)
                ui_color = 'green'
                final_draw.rectangle(ui_box, outline=ui_color, width=2)
                
                # –ü–æ–¥–ø–∏—Å—å –¥–ª—è UI —ç–ª–µ–º–µ–Ω—Ç–∞
                ui_label = f"UI{i+1}: {element.get('type', 'unknown')}"
                ui_label_x = ui_box[0] + 3
                ui_label_y = ui_box[1] - 20 if ui_box[1] > legend_height + 20 else ui_box[3] + 3
                
                # –ü–æ–¥–ª–æ–∂–∫–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ UI —ç–ª–µ–º–µ–Ω—Ç–∞
                ui_text_bbox = final_draw.textbbox((ui_label_x, ui_label_y), ui_label, font=small_font)
                final_draw.rectangle([ui_text_bbox[0]-2, ui_text_bbox[1]-1, ui_text_bbox[2]+2, ui_text_bbox[3]+1], 
                                    fill='lightgreen', outline=ui_color, width=1)
                
                # –¢–µ–∫—Å—Ç –ø–æ–¥–ø–∏—Å–∏ UI —ç–ª–µ–º–µ–Ω—Ç–∞
                final_draw.text((ui_label_x, ui_label_y), ui_label, fill=ui_color, font=small_font)
          # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –ø—Ä–∞–≤—ã–π –≤–µ—Ä—Ö–Ω–∏–π —É–≥–æ–ª
        ui_count = len(ui_analysis["ui_elements"]) if ui_analysis and ui_analysis.get("ui_elements") else 0
        stats_text = [
            f"–†–∞–∑–º–µ—Ä: {img_width}x{img_height}",
            f"–û–±—ä–µ–∫—Ç–æ–≤: {len(objects)}",
            f"–¢–µ–∫—Å—Ç–∞: {len(texts)-1 if texts and len(texts) > 1 else 0}",
            f"UI —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {ui_count}"
        ]
        
        stats_x = img_width - 200
        for i, stat in enumerate(stats_text):
            final_draw.text((stats_x, 60 + i*20), stat, fill='gray', font=small_font)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        final_img.save(output_path, quality=95)
        print(f"–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        final_img.show()
        return output_path
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return None

def classify_ui_element(bbox, text_content="", image_context=None):
    """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç UI —ç–ª–µ–º–µ–Ω—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    
    # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–∞ –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
    width = bbox[2] - bbox[0]
    height = bbox[3] - bbox[1]
    aspect_ratio = width / height if height > 0 else 1
    area = width * height
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
    text_lower = text_content.lower().strip()
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ —Ç–µ–∫—Å—Ç–µ
    if any(word in text_lower for word in ['start', 'play', 'begin', 'continue', 'resume']):
        return 'action_button'
    elif any(word in text_lower for word in ['menu', 'options', 'settings', 'config']):
        return 'menu_button'
    elif any(word in text_lower for word in ['close', 'exit', 'quit', 'cancel']):
        return 'close_button'
    elif any(word in text_lower for word in ['back', 'return', 'previous']):
        return 'back_button'
    elif any(word in text_lower for word in ['next', 'continue', 'proceed']):
        return 'navigation_button'
    elif any(word in text_lower for word in ['buy', 'purchase', 'shop', 'store']):
        return 'shop_button'
    elif any(word in text_lower for word in ['inventory', 'items', 'equipment']):
        return 'inventory_button'
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —Ä–∞–∑–º–µ—Ä—É –∏ –ø—Ä–æ–ø–æ—Ä—Ü–∏—è–º
    if area > 5000:  # –ë–æ–ª—å—à–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        if aspect_ratio > 3:  # –®–∏—Ä–æ–∫–∏–µ - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –ø–∞–Ω–µ–ª–∏ –∏–ª–∏ –ø–æ–ª–æ—Å—ã
            if any(word in text_lower for word in ['health', 'hp', 'life']):
                return 'health_bar'
            elif any(word in text_lower for word in ['mana', 'mp', 'magic']):
                return 'mana_bar'
            elif any(word in text_lower for word in ['experience', 'exp', 'xp']):
                return 'experience_bar'
            else:
                return 'panel'
        elif 0.8 < aspect_ratio < 1.2:  # –ö–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ - –∏–∫–æ–Ω–∫–∏ –∏–ª–∏ –∫–Ω–æ–ø–∫–∏
            return 'icon' if area < 10000 else 'button'
        else:
            return 'panel'
    
    elif 500 < area < 5000:  # –°—Ä–µ–¥–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        if aspect_ratio > 2:  # –®–∏—Ä–æ–∫–∏–µ - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –∫–Ω–æ–ø–∫–∏ –∏–ª–∏ –ø–æ–ª—è –≤–≤–æ–¥–∞
            if text_content and len(text_content) > 2:
                return 'button'
            else:
                return 'input_field'
        elif 0.5 < aspect_ratio < 2:  # –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
            return 'button' if text_content else 'icon'
    
    else:  # –ú–∞–ª–µ–Ω—å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        if text_content:
            return 'text_label'
        else:
            return 'icon'
    
    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    return 'ui_element'

def convert_vision_to_ui_elements(vision_objects, vision_texts, image_path=None):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã Vision API –≤ UI —ç–ª–µ–º–µ–Ω—Ç—ã —Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π"""
    ui_elements = []
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    img_width, img_height = 1920, 1080  # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if image_path:
        try:
            with Image.open(image_path) as img:
                img_width, img_height = img.size
        except Exception:
            pass
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±—ä–µ–∫—Ç—ã Vision API
    for obj in vision_objects:
        vertices = obj.bounding_poly.normalized_vertices
        bbox = [
            int(vertices[0].x * img_width), 
            int(vertices[0].y * img_height),
            int(vertices[2].x * img_width), 
            int(vertices[2].y * img_height)
        ]
        
        predicted_type = classify_ui_element(bbox, obj.name)
        
        element = UIElementAnnotation(
            bbox=bbox,
            predicted_type=predicted_type,
            confidence=obj.score,
            text=obj.name,
            context="vision_api_object"
        )
        ui_elements.append(element)
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏
    if vision_texts and len(vision_texts) > 1:
        for text_block in vision_texts[1:]:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç (–≤–µ—Å—å —Ç–µ–∫—Å—Ç)
            vertices = text_block.bounding_poly.vertices
            bbox = [
                min(v.x for v in vertices),
                min(v.y for v in vertices),
                max(v.x for v in vertices),
                max(v.y for v in vertices)
            ]
            
            predicted_type = classify_ui_element(bbox, text_block.description)
            
            element = UIElementAnnotation(
                bbox=bbox,
                predicted_type=predicted_type,
                confidence=0.8,  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                text=text_block.description,
                context="vision_api_text"
            )
            ui_elements.append(element)
    
    return ui_elements

def get_enhanced_user_feedback(ui_elements, annotated_image_path):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    print("\n" + "="*60)
    print("üéØ –°–û–ó–î–ê–ù–ò–ï –û–ë–£–ß–ê–Æ–©–ï–ì–û –î–ê–¢–ê–°–ï–¢–ê")
    print("="*60)
    print(f"üì∑ –ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {annotated_image_path}")
    print("\nüìã –ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
    for i, element in enumerate(ui_elements, 1):
        print(f"   {i}. {element.predicted_type} (—Ç–µ–∫—Å—Ç: '{element.text[:30]}{'...' if len(element.text) > 30 else ''}')")
    
    print("\n" + "-"*60)
    print("–ü–æ–º–æ–≥–∏—Ç–µ —É–ª—É—á—à–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ, —É–∫–∞–∑–∞–≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏–ø—ã —ç–ª–µ–º–µ–Ω—Ç–æ–≤:")
    print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    for category, tags in MOBILE_GAMING_UI_TAXONOMY.items():
        print(f"\nüè∑Ô∏è  {category.upper()}:")
        print(f"   {', '.join(tags[:8])}")  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 8 —Ç–µ–≥–æ–≤
        if len(tags) > 8:
            print(f"   ... –∏ –µ—â–µ {len(tags) - 8} —Ç–µ–≥–æ–≤")
    
    print("\n" + "-"*60)
    
    # –°–æ–±–∏—Ä–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    corrections = {}
    skip_all = False
    
    for i, element in enumerate(ui_elements):
        if skip_all:
            break
            
        print(f"\nüìù –≠–ª–µ–º–µ–Ω—Ç {i+1}/{len(ui_elements)}:")
        print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {element.predicted_type}")
        print(f"   –¢–µ–∫—Å—Ç: '{element.text}'")
        print(f"   –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: {element.bbox}")
        
        choice = input("   –í–≤–µ–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø (–∏–ª–∏ 'skip'/'all' –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip().lower()
        
        if choice == 'skip':
            continue
        elif choice == 'all':
            skip_all = True
            break
        elif choice in ALL_UI_TAGS:
            corrections[i] = choice
            element.actual_type = choice
            print(f"   ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –Ω–∞: {choice}")
        elif choice:
            # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ–≥–æ–≤
            similar_tags = [tag for tag in ALL_UI_TAGS if choice in tag or tag in choice]
            if similar_tags:
                print(f"   üîç –ü–æ—Ö–æ–∂–∏–µ —Ç–µ–≥–∏: {', '.join(similar_tags[:5])}")
                confirm = input(f"   –í–æ–∑–º–æ–∂–Ω–æ, –≤—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É '{similar_tags[0]}'? (y/n): ").strip().lower()
                if confirm == 'y':
                    corrections[i] = similar_tags[0]
                    element.actual_type = similar_tags[0]
                    print(f"   ‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: {similar_tags[0]}")
      # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
    print("\n" + "-"*60)
    overall_quality = input("–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (1-5): ").strip()
    additional_comments = input("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏: ").strip()
    
    feedback = {
        "overall_quality": overall_quality,
        "corrections_count": len(corrections),
        "total_elements": len(ui_elements),
        "accuracy": (len(ui_elements) - len(corrections)) / len(ui_elements) if ui_elements else 0,
        "comments": additional_comments,
        "corrections": corrections
    }
    
    print(f"\n‚úÖ –°–ø–∞—Å–∏–±–æ! –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ {len(corrections)} –∏–∑ {len(ui_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
    print("="*60)
    
    return feedback

def get_user_feedback(annotated_image_path, objects, texts):
    """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å."""
    print("\n" + "="*50)
    print("–û–¶–ï–ù–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ê–ù–ê–õ–ò–ó–ê")
    print("="*50)
    print(f"üì∑ –ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {annotated_image_path}")
    print("\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–∫—Ä–æ–π—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–∞.")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–≤–æ–¥–∫—É –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤:")
    print(f"   ‚Ä¢ –û–±—ä–µ–∫—Ç–æ–≤: {len(objects) if objects else 0}")
    print(f"   ‚Ä¢ –¢–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤: {len(texts)-1 if texts and len(texts) > 1 else 0}")
    print("-"*50)

    all_correct = input("–ö–∞—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–∞ (–æ—Ç–ª–∏—á–Ω–æ/—Ö–æ—Ä–æ—à–æ/—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ/–ø–ª–æ—Ö–æ): ")

    feedback_data = {
        "overall_correctness": all_correct,
        "comments": "",
        "object_feedback": [],
        "text_feedback": []
    }

    if all_correct in ["—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ", "–ø–ª–æ—Ö–æ"]:
        print("\n–ü–æ–º–æ–≥–∏—Ç–µ —É–ª—É—á—à–∏—Ç—å –∞–Ω–∞–ª–∏–∑:")
        feedback_data["comments"] = input("‚Ä¢ –ß—Ç–æ –±—ã–ª–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –Ω–µ–≤–µ—Ä–Ω–æ? ")
        missing_elements = input("‚Ä¢ –ö–∞–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–µ –±—ã–ª–∏ –Ω–∞–π–¥–µ–Ω—ã? ")
        if missing_elements:
            feedback_data["comments"] += f" –ü—Ä–æ–ø—É—â–µ–Ω–æ: {missing_elements}"

    print("\n‚úÖ –°–ø–∞—Å–∏–±–æ –∑–∞ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å! –û–Ω–∞ –ø–æ–º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º.")
    return feedback_data

def save_learning_data(original_image_path, vision_objects, vision_texts, user_feedback, data_folder="learning_data"):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è '–æ–±—É—á–µ–Ω–∏—è' (—Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö)."""
    if not os.path.exists(data_folder):
        os.makedirs(data_folder)
    
    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è –¥–ª—è –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞ –æ—Å–Ω–æ–≤–µ timestamp)
    import time
    timestamp = time.strftime("%Y%m%d-%H%M%S")
    entry_folder = os.path.join(data_folder, f"entry_{timestamp}")
    os.makedirs(entry_folder)

    # –ö–æ–ø–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    from shutil import copy
    base_image_name = os.path.basename(original_image_path)
    copied_image_path = os.path.join(entry_folder, base_image_name)
    copy(original_image_path, copied_image_path)    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã Vision API –∏ —Ñ–∏–¥–±–µ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ JSON)
    import json
    data_to_save = {
        "original_image_path_in_entry": base_image_name,
        "vision_api_objects": [{"name": o.name, "score": o.score, "vertices": [(v.x, v.y) for v in o.bounding_poly.normalized_vertices]} for o in vision_objects],
        "vision_api_texts": [{"description": t.description, "vertices": [(v.x, v.y) for v in t.bounding_poly.vertices]} for t in (vision_texts[1:] if vision_texts else [])],
        "user_feedback": user_feedback
    }
    
    with open(os.path.join(entry_folder, "data.json"), "w", encoding="utf-8") as f:
        json.dump(data_to_save, f, indent=4, ensure_ascii=False)
    
    print(f"–î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {entry_folder}")


# --- –§—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞ UI —ç–ª–µ–º–µ–Ω—Ç–æ–≤ ---

def analyze_ui_elements(image_path):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç UI —ç–ª–µ–º–µ–Ω—Ç—ã –±–µ–∑ OpenCV - –∏—Å–ø–æ–ª—å–∑—É—è PIL –∏ –±–∞–∑–æ–≤—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã."""
    try:
        from PIL import Image, ImageStat
        import numpy as np
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        img = Image.open(image_path)
        print(f"   –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img.size[0]}x{img.size[1]} –ø–∏–∫—Å–µ–ª–µ–π")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ RGB –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        if img.mode != 'RGB':
            img = img.convert('RGB')
            
        # 1. –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ü–≤–µ—Ç–æ–≤
        color_analysis = analyze_colors_simple(img)
        
        # 2. –ü–æ–∏—Å–∫ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∫–Ω–æ–ø–∫–∏/–ø–æ–ª—è)
        ui_elements = find_rectangular_regions(img)
        
        # 3. –ê–Ω–∞–ª–∏–∑ –æ–±—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        layout_analysis = analyze_layout_structure(img)
        
        print(f"   –ù–∞–π–¥–µ–Ω–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö UI —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(ui_elements)}")
        
        return {
            "color_analysis": color_analysis,
            "ui_elements": ui_elements,
            "layout_analysis": layout_analysis,
            "image_size": img.size
        }
        
    except Exception as e:
        print(f"   –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ UI —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {e}")
        return {
            "color_analysis": {},
            "ui_elements": [],
            "layout_analysis": {},
            "image_size": (0, 0)
        }

def analyze_colors_simple(img):
    """–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ü–≤–µ—Ç–æ–≤–æ–π —Å—Ö–µ–º—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ü–≤–µ—Ç–∞–º
        width, height = img.size
        pixels = list(img.getdata())
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–µ —Ü–≤–µ—Ç–∞
        color_counts = {}
        for pixel in pixels[::100]:  # –ë–µ—Ä–µ–º –∫–∞–∂–¥—ã–π 100-–π –ø–∏–∫—Å–µ–ª—å –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            color_counts[pixel] = color_counts.get(pixel, 0) + 1
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ
        sorted_colors = sorted(color_counts.items(), key=lambda x: x[1], reverse=True)
        dominant_colors = sorted_colors[:5]  # –¢–æ–ø 5 —Ü–≤–µ—Ç–æ–≤
        
        return {
            "dominant_colors": dominant_colors,
            "total_unique_colors": len(color_counts),
            "analysis": "–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ü–≤–µ—Ç–æ–≤"
        }
    except Exception as e:
        return {"error": str(e)}

def find_rectangular_regions(img):
    """–ù–∞—Ö–æ–¥–∏—Ç –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å UI —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏."""
    try:
        import numpy as np
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –º–∞—Å—Å–∏–≤ numpy
        img_array = np.array(img)
        width, height = img.size
        
        # –ò—â–µ–º –æ–±–ª–∞—Å—Ç–∏ —Å –æ–¥–Ω–æ—Ä–æ–¥–Ω—ã–º–∏ —Ü–≤–µ—Ç–∞–º–∏ (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∫–Ω–æ–ø–∫–∏)
        ui_elements = []
          # –ü—Ä–æ—Å—Ç–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º: —Ä–∞–∑–±–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ —Å–µ—Ç–∫—É –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –±–ª–æ–∫
        block_size = 80  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ (–±—ã–ª–æ 50)
        min_variance_threshold = 500  # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç–∏ (–±—ã–ª–æ 1000)
        
        for y in range(0, height - block_size, block_size // 2):  # –ú–µ–Ω—å—à–µ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
            for x in range(0, width - block_size, block_size // 2):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–ª–æ–∫
                block = img_array[y:y+block_size, x:x+block_size]
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç—å —Ü–≤–µ—Ç–∞
                avg_color = np.mean(block, axis=(0, 1))
                color_variance = np.var(block, axis=(0, 1))
                
                # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è UI —ç–ª–µ–º–µ–Ω—Ç–∞
                total_variance = np.sum(color_variance)
                if total_variance < min_variance_threshold:
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –Ω–µ —Å–ª–∏—à–∫–æ–º –ª–∏ —Ç–µ–º–Ω—ã–π/—Å–≤–µ—Ç–ª—ã–π
                    brightness = np.mean(avg_color)
                    if 30 < brightness < 220:  # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª–∏—à–∫–æ–º —Ç–µ–º–Ω—ã–µ/—Å–≤–µ—Ç–ª—ã–µ –æ–±–ª–∞—Å—Ç–∏
                        ui_elements.append({
                            "type": "potential_ui_element",
                            "bounds": (x, y, x+block_size, y+block_size),
                            "avg_color": avg_color.tolist(),
                            "confidence": min(0.8, 1.0 - (total_variance / min_variance_threshold))
                        })
        
        return ui_elements
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π: {e}")
        return []

def analyze_layout_structure(img):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–∞–∫–µ—Ç–∞."""
    try:
        width, height = img.size
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–∞–∫–µ—Ç–∞ –ø–æ –ø—Ä–æ–ø–æ—Ä—Ü–∏—è–º
        aspect_ratio = width / height
        
        if aspect_ratio > 1.5:
            layout_type = "landscape"
        elif aspect_ratio < 0.7:
            layout_type = "portrait"
        else:
            layout_type = "square"
        
        return {
            "type": layout_type,
            "aspect_ratio": aspect_ratio,
            "dimensions": f"{width}x{height}",
            "analysis": "–ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –º–∞–∫–µ—Ç–∞"
        }
        
    except Exception as e:
        return {"error": str(e)}

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ ---

def analyze_color_type(rgb_color):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ü–≤–µ—Ç–∞ (—Å–≤–µ—Ç–ª—ã–π, —Ç–µ–º–Ω—ã–π, —è—Ä–∫–∏–π, –ø—Ä–∏–≥–ª—É—à–µ–Ω–Ω—ã–π)."""
    r, g, b = rgb_color
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ HSV –¥–ª—è –ª—É—á—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    h, s, v = colorsys.rgb_to_hsv(r/255.0, g/255.0, b/255.0)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è—Ä–∫–æ—Å—Ç—å
    brightness = v
    saturation = s
    
    if brightness > 0.8:
        if saturation < 0.2:
            return "light_neutral"  # –°–≤–µ—Ç–ª—ã–π –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π (–±–µ–ª—ã–π, —Å–≤–µ—Ç–ª–æ-—Å–µ—Ä—ã–π)
        else:
            return "light_vibrant"  # –°–≤–µ—Ç–ª—ã–π —è—Ä–∫–∏–π
    elif brightness < 0.3:
        if saturation < 0.2:
            return "dark_neutral"   # –¢–µ–º–Ω—ã–π –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π (—á–µ—Ä–Ω—ã–π, —Ç–µ–º–Ω–æ-—Å–µ—Ä—ã–π)
        else:
            return "dark_vibrant"   # –¢–µ–º–Ω—ã–π —è—Ä–∫–∏–π
    else:
        if saturation > 0.6:
            return "vibrant"        # –Ø—Ä–∫–∏–π —Å—Ä–µ–¥–Ω–∏–π
        else:
            return "muted"          # –ü—Ä–∏–≥–ª—É—à–µ–Ω–Ω—ã–π —Å—Ä–µ–¥–Ω–∏–π

def determine_color_scheme_type(color_data):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ü–≤–µ—Ç–æ–≤–æ–π —Å—Ö–µ–º—ã."""
    light_count = sum(1 for c in color_data if "light" in c["color_type"])
    dark_count = sum(1 for c in color_data if "dark" in c["color_type"])
    vibrant_count = sum(1 for c in color_data if "vibrant" in c["color_type"])
    
    if light_count > dark_count:
        if vibrant_count > 2:
            return "light_colorful"
        else:
            return "light_minimal"
    else:
        if vibrant_count > 2:
            return "dark_colorful"
        else:
            return "dark_minimal"

# --- –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞ ---
def main():
    print("\n" + "="*60)
    print("        AI-–ê–ì–ï–ù–¢ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê UI –≠–õ–ï–ú–ï–ù–¢–û–í")
    print("="*60)
    print("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:")
    print("1. üìä –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è UI")
    print("2. üî¨ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –Ω–∞ GitHub")
    print("3. ‚ùå –í—ã—Ö–æ–¥")
    print("="*60)
    
    choice = input("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä (1-3): ").strip()
    
    if choice == "2":
        research_ui_algorithms()
        return
    elif choice == "3":
        print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
        return
    elif choice != "1":
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
    
    print("\n" + "="*60)
    print("        –†–ï–ñ–ò–ú –ê–ù–ê–õ–ò–ó–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø")
    print("="*60)
    print("–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:")
    print("‚Ä¢ Google Vision API - –ø–æ–∏—Å–∫ —Ç–µ–∫—Å—Ç–∞ –∏ –æ–±—ä–µ–∫—Ç–æ–≤")
    print("‚Ä¢ –ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ - –∞–Ω–∞–ª–∏–∑ —Ñ–æ—Ä–º –∏ –∫–æ–Ω—Ç—É—Ä–æ–≤") 
    print("‚Ä¢ –ê–Ω–∞–ª–∏–∑ —Ü–≤–µ—Ç–æ–≤—ã—Ö —Å—Ö–µ–º")
    print("="*60)

    # 1. –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    print("\n[1] –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
    original_image_path = get_image_from_user()
    if not original_image_path:
        return    # 2. –ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é Google Vision API
    print("\n[2] –ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é Google Vision API...")
    objects, texts = analyze_image_with_vision_ai(original_image_path)
    if objects is None and texts is None:
        print("\n‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç Vision API")
        return
      # 3. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ UI —ç–ª–µ–º–µ–Ω—Ç—ã —Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
    print("\n[3] –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è UI —ç–ª–µ–º–µ–Ω—Ç–æ–≤...")
    ui_elements = convert_vision_to_ui_elements(objects or [], texts or [], original_image_path)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    if ui_elements:
        print(f"üéØ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(ui_elements)}")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º
        type_counts = {}
        for element in ui_elements:
            element_type = element.predicted_type
            type_counts[element_type] = type_counts.get(element_type, 0) + 1
        
        print("üìã –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–∏–ø—ã —ç–ª–µ–º–µ–Ω—Ç–æ–≤:")
        for element_type, count in sorted(type_counts.items()):
            print(f"   ‚Ä¢ {element_type}: {count}")
    else:
        print("‚ö†Ô∏è  –≠–ª–µ–º–µ–Ω—Ç—ã UI –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
      
    # 4. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ UI —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (—Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
    print("\n[4] –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑...")
    ui_analysis = analyze_ui_elements(original_image_path)
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ UI
    if ui_analysis and ui_analysis.get("ui_elements"):
        print("\n" + "="*50)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê UI –≠–õ–ï–ú–ï–ù–¢–û–í")
        print("="*50)
        
        ui_elements = ui_analysis["ui_elements"]
        print(f"üî≤ –ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ï UI –≠–õ–ï–ú–ï–ù–¢–´: {len(ui_elements)}")
        
        if ui_elements:
            for i, element in enumerate(ui_elements[:5], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                bounds = element.get("bounds", [0, 0, 0, 0])
                width = bounds[2] - bounds[0]
                height = bounds[3] - bounds[1]
                print(f"   {i}. {element.get('type', 'unknown')} - {width}x{height}px")
            
            if len(ui_elements) > 5:
                print(f"   ... –∏ –µ—â–µ {len(ui_elements) - 5} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
        
        # –í—ã–≤–æ–¥–∏–º –∞–Ω–∞–ª–∏–∑ –º–∞–∫–µ—Ç–∞
        layout = ui_analysis.get("layout_analysis", {})
        if layout:
            print(f"\nüìê –ú–ê–ö–ï–¢: {layout.get('type', 'unknown')} ({layout.get('dimensions', 'unknown')})")
        
        # –í—ã–≤–æ–¥–∏–º —Ü–≤–µ—Ç–æ–≤—É—é —Å—Ö–µ–º—É
        colors = ui_analysis.get("color_analysis", {})
        if colors and colors.get("dominant_colors"):
            print(f"\nüé® –î–û–ú–ò–ù–ò–†–£–Æ–©–ò–ï –¶–í–ï–¢–ê: {len(colors['dominant_colors'])} –Ω–∞–π–¥–µ–Ω–æ")
            
        print("="*50)
      # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
    has_ui_elements = len(ui_elements) > 0
    has_additional_ui = ui_analysis and ui_analysis.get("ui_elements") and len(ui_analysis["ui_elements"]) > 0
    
    if not has_ui_elements and not has_additional_ui:
        print("\n" + "="*50)
        print("‚ö†Ô∏è  –†–ï–ó–£–õ–¨–¢–ê–¢: –≠–ª–µ–º–µ–Ω—Ç—ã UI –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        print("="*50)
        user_expects_elements = input("–û–∂–∏–¥–∞–ª–∏ –ª–∏ –≤—ã –Ω–∞–π—Ç–∏ UI —ç–ª–µ–º–µ–Ω—Ç—ã? (–¥–∞/–Ω–µ—Ç): ").strip().lower()
        if user_expects_elements == '–¥–∞':
            print("\n–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
            print("‚Ä¢ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º —Ä–∞–∑–º—ã—Ç–æ–µ –∏–ª–∏ —Å–ª–æ–∂–Ω–æ–µ")
            print("‚Ä¢ –ù–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –¥–∏–∑–∞–π–Ω –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞") 
            print("‚Ä¢ –¢—Ä–µ–±—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∞–Ω–∞–ª–∏–∑–∞")
        print("="*50)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º "–ø—É—Å—Ç–æ–π" —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        feedback_for_empty = {
            "overall_correctness": "–ø–ª–æ—Ö–æ (–Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ)", 
            "comments": "–ê–≥–µ–Ω—Ç –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ UI —ç–ª–µ–º–µ–Ω—Ç—ã",
            "expected_elements": user_expects_elements == '–¥–∞'
        }
        save_enhanced_learning_data(original_image_path, ui_elements, ui_analysis, feedback_for_empty)
        return

    # 5. –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    print("\n[5] –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
    annotated_image_file = draw_annotations(original_image_path, 
        objects or [], 
        texts or [], 
        "enhanced_annotated_image.png",
        ui_analysis
    )
    
    if not annotated_image_file:
        print("‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        return

    # 6. –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
    print("\n[6] –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—É—á–∞—é—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    
    # –í—ã–±–æ—Ä –º–µ–∂–¥—É –ø—Ä–æ—Å—Ç–æ–π –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é
    feedback_mode = input("–†–µ–∂–∏–º –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ (–ø—Ä–æ—Å—Ç–æ–π/–¥–∞—Ç–∞—Å–µ—Ç): ").strip().lower()
    
    if feedback_mode == '–¥–∞—Ç–∞—Å–µ—Ç':
        user_feedback = get_enhanced_user_feedback(ui_elements, annotated_image_file)
        save_enhanced_learning_data(original_image_path, ui_elements, ui_analysis, user_feedback)
    else:
        user_feedback = get_user_feedback(annotated_image_file, objects or [], texts or [])
        save_learning_data(original_image_path, objects or [], texts or [], user_feedback)

    print("\n" + "="*60)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
    print("="*60)
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"‚Ä¢ –ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {annotated_image_file}")
    print(f"‚Ä¢ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(ui_elements)}")
    print("‚Ä¢ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
    print("‚Ä¢ –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å —É—á—Ç–µ–Ω–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤")
    print("="*60)

if __name__ == "__main__":
    main()

def draw_enhanced_annotations(image_path, vision_objects, vision_texts, ui_analysis, output_path="enhanced_annotated_output.png"):
    """–†–∏—Å—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º UI —ç–ª–µ–º–µ–Ω—Ç–æ–≤."""
    try:
        pil_image = Image.open(image_path).convert("RGBA")
        draw = ImageDraw.Draw(pil_image)
        img_width, img_height = pil_image.size
        
        try:
            font = ImageFont.truetype("arial.ttf", 12)
            title_font = ImageFont.truetype("arial.ttf", 16)
        except IOError:
            font = ImageFont.load_default()
            title_font = ImageFont.load_default()

        # –†–∏—Å—É–µ–º UI —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ
        if ui_analysis and ui_analysis.get("ui_elements"):
            for i, element in enumerate(ui_analysis["ui_elements"]):
                x, y = element["position"]
                w, h = element["size"]
                element_type = element["type"]
                
                # –í—ã–±–∏—Ä–∞–µ–º —Ü–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ —ç–ª–µ–º–µ–Ω—Ç–∞
                color_map = {
                    "button": "red",
                    "navigation_bar": "orange", 
                    "sidebar": "purple",
                    "panel": "cyan",
                    "text_area": "yellow",
                    "icon_button": "pink",
                    "large_button": "magenta"
                }
                box_color = color_map.get(element_type, "blue")
                
                # –†–∏—Å—É–µ–º —Ä–∞–º–∫—É
                draw.rectangle([x, y, x + w, y + h], outline=box_color, width=3)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∫—É —Å —Ç–∏–ø–æ–º —ç–ª–µ–º–µ–Ω—Ç–∞
                label = f"UI_{i}: {element_type}"
                text_position = (x + 2, y + 2 if y < img_height - 40 else y - 20)
                draw.text(text_position, label, fill=box_color, font=font)

        # –†–∏—Å—É–µ–º –æ–±—ä–µ–∫—Ç—ã –æ—Ç Vision API (—Å–∏–Ω–∏–º)
        if vision_objects:
            for i, obj in enumerate(vision_objects):
                box_color = "blue"
                vertices = obj.bounding_poly.normalized_vertices
                box = [
                    vertices[0].x * img_width, vertices[0].y * img_height,
                    vertices[2].x * img_width, vertices[2].y * img_height
                ]
                draw.rectangle(box, outline=box_color, width=2)
                label = f"Obj: {obj.name} ({obj.score:.2f})"
                text_position = (box[0] + 2, box[1] + 2 if box[1] < img_height - 20 else box[1] - 20)
                draw.text(text_position, label, fill=box_color, font=font)

        # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ –æ—Ç Vision API (–∑–µ–ª–µ–Ω—ã–º)
        if vision_texts and len(vision_texts) > 1:
            for i, text_block in enumerate(vision_texts[1:]):
                box_color = "green"
                vertices = text_block.bounding_poly.vertices
                x_coords = [v.x for v in vertices]
                y_coords = [v.y for v in vertices]
                box = [min(x_coords), min(y_coords), max(x_coords), max(y_coords)]
                
                draw.rectangle(box, outline=box_color, width=1)
                label = f"Txt: {text_block.description.replace(chr(10), ' ')}"[:25]
                text_position = (box[0] + 2, box[1] + 2 if box[1] < img_height - 20 else box[1] - 20)
                draw.text(text_position, label, fill=box_color, font=font)

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ü–≤–µ—Ç–æ–≤–æ–π —Å—Ö–µ–º–µ
        if ui_analysis and ui_analysis.get("color_analysis"):
            color_info = ui_analysis["color_analysis"]
            scheme_type = color_info.get("color_scheme_type", "unknown")
            
            # –†–∏—Å—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ü–≤–µ—Ç–æ–≤–æ–π —Å—Ö–µ–º–µ –≤ —É–≥–ª—É
            info_text = f"–¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞: {scheme_type}"
            draw.text((10, 10), info_text, fill="black", font=title_font)
            
            # –†–∏—Å—É–µ–º –ø–∞–ª–∏—Ç—Ä—É –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏—Ö —Ü–≤–µ—Ç–æ–≤
            if "dominant_colors" in color_info:
                for i, color_data in enumerate(color_info["dominant_colors"][:5]):
                    color_rgb = tuple(color_data["rgb"])
                    x_pos = 10 + i * 40
                    y_pos = 35
                    draw.rectangle([x_pos, y_pos, x_pos + 30, y_pos + 20], fill=color_rgb, outline="black")
                    draw.text((x_pos, y_pos + 25), f"{color_data['percentage']:.1f}%", fill="black", font=font)

        pil_image.save(output_path)
        print(f"–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫: {output_path}")
        pil_image.show()
        return output_path
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π: {e}")
        return None

def get_enhanced_user_feedback(annotated_image_path, vision_objects, vision_texts, ui_analysis):
    """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å —Å —É—á–µ—Ç–æ–º UI –∞–Ω–∞–ª–∏–∑–∞."""
    print("\n=== –†–ê–°–®–ò–†–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó UI –≠–õ–ï–ú–ï–ù–¢–û–í ===")
    print(f"–ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {annotated_image_path}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    ui_count = len(ui_analysis.get("ui_elements", [])) if ui_analysis else 0
    vision_obj_count = len(vision_objects) if vision_objects else 0
    vision_text_count = len(vision_texts) - 1 if vision_texts and len(vision_texts) > 1 else 0
    
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞:")
    print(f"  üî∏ UI —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (–∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ): {ui_count}")
    print(f"  üîπ –û–±—ä–µ–∫—Ç–æ–≤ (Vision API): {vision_obj_count}")  
    print(f"  üîπ –¢–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤ (Vision API): {vision_text_count}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ü–≤–µ—Ç–æ–≤–æ–π —Å—Ö–µ–º–µ
    if ui_analysis and ui_analysis.get("color_analysis"):
        color_info = ui_analysis["color_analysis"]
        print(f"  üé® –¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞: {color_info.get('color_scheme_type', '–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞')}")
        
        if "dominant_colors" in color_info:
            print("  üé® –î–æ–º–∏–Ω–∏—Ä—É—é—â–∏–µ —Ü–≤–µ—Ç–∞:")
            for i, color_data in enumerate(color_info["dominant_colors"][:3]):
                print(f"     {i+1}. {color_data['hex']} ({color_data['percentage']:.1f}%) - {color_data['color_type']}")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∏–ø—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö UI —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    if ui_analysis and ui_analysis.get("ui_elements"):
        element_types = {}
        for element in ui_analysis["ui_elements"]:
            elem_type = element["type"]
            element_types[elem_type] = element_types.get(elem_type, 0) + 1
        
        print("  üì± –¢–∏–ø—ã UI —ç–ª–µ–º–µ–Ω—Ç–æ–≤:")
        for elem_type, count in element_types.items():
            print(f"     - {elem_type}: {count}")

    # –ü–æ–ª—É—á–∞–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
    print("\n=== –û–ë–†–ê–¢–ù–ê–Ø –°–í–Ø–ó–¨ ===")
    overall_correct = input("–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞ UI (–æ—Ç–ª–∏—á–Ω–æ/—Ö–æ—Ä–æ—à–æ/—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ/–ø–ª–æ—Ö–æ): ").strip().lower()
    
    feedback_data = {
        "overall_correctness": overall_correct,
        "ui_elements_feedback": {},
        "color_scheme_feedback": {},
        "suggestions": "",
        "missing_elements": "",
        "statistics": {
            "ui_elements_found": ui_count,
            "vision_objects_found": vision_obj_count,
            "vision_texts_found": vision_text_count
        }
    }

    if overall_correct in ["—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ", "–ø–ª–æ—Ö–æ"]:
        print("\n–î–∞–≤–∞–π—Ç–µ —É—Ç–æ—á–Ω–∏–º –¥–µ—Ç–∞–ª–∏:")
        
        # –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –ø–æ UI —ç–ª–µ–º–µ–Ω—Ç–∞–º
        ui_elements_correct = input("UI —ç–ª–µ–º–µ–Ω—Ç—ã (–∫—Ä–∞—Å–Ω—ã–µ/–æ—Ä–∞–Ω–∂–µ–≤—ã–µ/—Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–µ —Ä–∞–º–∫–∏) –Ω–∞–π–¥–µ–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ? (–¥–∞/–Ω–µ—Ç/—á–∞—Å—Ç–∏—á–Ω–æ): ").strip().lower()
        feedback_data["ui_elements_feedback"]["correctness"] = ui_elements_correct
        
        if ui_elements_correct != "–¥–∞":
            missing = input("–ö–∞–∫–∏–µ UI —ç–ª–µ–º–µ–Ω—Ç—ã –ø—Ä–æ–ø—É—â–µ–Ω—ã? (–∫–Ω–æ–ø–∫–∏/–ø–∞–Ω–µ–ª–∏/–º–µ–Ω—é/–æ–∫–Ω–∞/–¥—Ä—É–≥–æ–µ): ")
            feedback_data["missing_elements"] = missing
            
            incorrect = input("–ö–∞–∫–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–µ–≤–µ—Ä–Ω—ã?: ")
            feedback_data["ui_elements_feedback"]["incorrect"] = incorrect

        # –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –ø–æ —Ü–≤–µ—Ç–æ–≤–æ–π —Å—Ö–µ–º–µ
        if ui_analysis and ui_analysis.get("color_analysis"):
            colors_correct = input("–¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ? (–¥–∞/–Ω–µ—Ç): ").strip().lower()
            feedback_data["color_scheme_feedback"]["correctness"] = colors_correct
            
            if colors_correct == "–Ω–µ—Ç":
                correct_scheme = input("–ö–∞–∫–∞—è —Ü–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è? (—Å–≤–µ—Ç–ª–∞—è/—Ç–µ–º–Ω–∞—è/—è—Ä–∫–∞—è/–º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è): ")
                feedback_data["color_scheme_feedback"]["correct_scheme"] = correct_scheme

        # –û–±—â–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        suggestions = input("–ï—Å—Ç—å –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∞–Ω–∞–ª–∏–∑–∞?: ")
        feedback_data["suggestions"] = suggestions

    print("–°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–¥—Ä–æ–±–Ω—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å!")
    return feedback_data

def save_enhanced_learning_data(original_image_path, ui_elements, ui_analysis, user_feedback):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –æ–±—É—á–µ–Ω–∏—è"""
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º dataset builder
    dataset_builder = DatasetBuilder()
    
    # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    metadata = {
        "image_path": original_image_path,
        "timestamp": datetime.datetime.now().isoformat(),
        "image_type": "mobile_gaming_ui",
        "analysis_version": "2.0_with_taxonomy",
        "user_feedback": user_feedback,
        "ui_analysis": ui_analysis
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é –≤ –¥–∞—Ç–∞—Å–µ—Ç
    annotation_id = dataset_builder.add_annotation(
        original_image_path, 
        ui_elements, 
        metadata
    )
    
    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è backward compatibility
    import time
    timestamp = time.strftime("%Y%m%d-%H%M%S")
    entry_folder = Path("learning_data") / f"enhanced_entry_{timestamp}"
    entry_folder.mkdir(parents=True, exist_ok=True)
    
    # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    from shutil import copy
    base_image_name = Path(original_image_path).name
    copied_image_path = entry_folder / base_image_name
    copy(original_image_path, copied_image_path)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ JSON
    detailed_data = {
        "annotation_id": annotation_id,
        "original_image": base_image_name,
        "ui_elements": [elem.to_dict() for elem in ui_elements],
        "taxonomy_used": MOBILE_GAMING_UI_TAXONOMY,
        "user_feedback": user_feedback,
        "additional_analysis": ui_analysis,
        "statistics": {
            "total_elements": len(ui_elements),
            "verified_elements": len([e for e in ui_elements if e.user_verified]),
            "unique_types": len(set(e.actual_type or e.predicted_type for e in ui_elements)),
            "accuracy": user_feedback.get('accuracy', 0)
        }
    }
    
    with open(entry_folder / "enhanced_data.json", "w", encoding="utf-8") as f:
        json.dump(detailed_data, f, indent=2, ensure_ascii=False)
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
    create_training_formats(ui_elements, original_image_path, entry_folder)
    
    print(f"‚úÖ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    print(f"   üìÅ –ü–∞–ø–∫–∞: {entry_folder}")
    print(f"   üÜî ID –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏: {annotation_id}")
    print(f"   üìä –≠–ª–µ–º–µ–Ω—Ç–æ–≤: {len(ui_elements)} (–ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {len([e for e in ui_elements if e.user_verified])})")

def create_training_formats(ui_elements, original_image_path, output_folder):
    """–°–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª—ã –≤ —Ñ–æ—Ä–º–∞—Ç–∞—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (YOLO, COCO –∏ —Ç.–¥.)"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤
    with Image.open(original_image_path) as img:
        img_width, img_height = img.size
    
    # –°–æ–∑–¥–∞–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã
    verified_elements = [e for e in ui_elements if e.user_verified and e.actual_type]
    
    if not verified_elements:
        print("   ‚ö†Ô∏è  –ù–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è")
        return
    
    # 1. –§–æ—Ä–º–∞—Ç YOLO
    yolo_file = output_folder / "yolo_annotation.txt"
    with open(yolo_file, 'w') as f:
        for element in verified_elements:
            class_id = get_class_id_for_type(element.actual_type)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è YOLO
            x_center = (element.bbox[0] + element.bbox[2]) / 2 / img_width
            y_center = (element.bbox[1] + element.bbox[3]) / 2 / img_height
            width = (element.bbox[2] - element.bbox[0]) / img_width
            height = (element.bbox[3] - element.bbox[1]) / img_height
            
            f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")
    
    # 2. –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –∫–ª–∞—Å—Å–∞–º–∏
    classes_file = output_folder / "classes.txt"
    unique_classes = sorted(set(e.actual_type for e in verified_elements))
    with open(classes_file, 'w') as f:
        for class_name in unique_classes:
            f.write(f"{class_name}\n")
    
    print(f"   üìÑ –°–æ–∑–¥–∞–Ω–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è: YOLO ({len(verified_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)")

def get_class_id_for_type(ui_type):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å–ª–æ–≤–æ–π ID –¥–ª—è —Ç–∏–ø–∞ UI —ç–ª–µ–º–µ–Ω—Ç–∞"""
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ç–∏–ø–æ–≤ –∏ ID
    if not hasattr(get_class_id_for_type, '_class_mapping'):
        all_types = sorted(set(ALL_UI_TAGS))
        get_class_id_for_type._class_mapping = {ui_type: i for i, ui_type in enumerate(all_types)}
    
    return get_class_id_for_type._class_mapping.get(ui_type, 0)

def research_ui_algorithms():
    """–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ UI –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ GitHub"""
    print("\nüî¨ === –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï –ê–õ–ì–û–†–ò–¢–ú–û–í UI –ê–ù–ê–õ–ò–ó–ê ===")
    print("–ü–æ–∏—Å–∫ –ª—É—á—à–∏—Ö —Ä–µ—à–µ–Ω–∏–π –Ω–∞ GitHub...")
    
    try:
        # –°–æ–∑–¥–∞–µ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è
        researcher = GitHubUIResearcher()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        print("üîç –ù–∞—á–∏–Ω–∞—é –ø–æ–∏—Å–∫ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...")
        repos = researcher.search_ui_analysis_repositories(max_results=20)
        
        if repos:
            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            researcher.print_research_summary(repos)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            saved_file = researcher.save_research_results(repos)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ø-3 —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ
            print("\nüî¨ –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –¢–û–ü-3 –†–ï–ü–û–ó–ò–¢–û–†–ò–ï–í:")
            print("=" * 50)
            
            for i, repo in enumerate(repos[:3], 1):
                print(f"\n{i}. {repo['name']} ({repo['stars']} ‚≠ê)")
                print(f"   üîó {repo['html_url']}")
                
                # –ü–æ–ª—É—á–∞–µ–º README
                readme = researcher.get_repository_readme(repo['full_name'])
                if readme:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –æ–ø–∏—Å–∞–Ω–∏—è
                    description = readme.replace('\n', ' ')[:200] + "..."
                    print(f"   üìÑ –û–ø–∏—Å–∞–Ω–∏–µ: {description}")
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ–¥–∞
                code_analysis = researcher.analyze_repository_code(repo['full_name'])
                if 'error' not in code_analysis:
                    print(f"   üìÅ –§–∞–π–ª–æ–≤: {code_analysis['total_files']}, "
                          f"–ö–æ–¥–∞: {code_analysis['code_files']}")
                    if code_analysis['key_files']:
                        print(f"   üîë –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã: {', '.join(code_analysis['key_files'][:3])}")
                
                print()
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
            print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–õ–£–ß–®–ï–ù–ò–Æ –ê–ì–ï–ù–¢–ê:")
            print("-" * 40)
            
            python_repos = [r for r in repos if r['language'] == 'Python']
            if python_repos:
                print(f"1. üêç –ò–∑—É—á–∏—Ç—å Python —Ä–µ—à–µ–Ω–∏—è ({len(python_repos)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤)")
                top_python = python_repos[0]
                print(f"   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: {top_python['name']} - {top_python['html_url']}")
            
            opencv_repos = [r for r in repos if 'opencv' in r['name'].lower() or 
                           'opencv' in r['description'].lower()]
            if opencv_repos:
                print(f"2. üëÅÔ∏è –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å OpenCV –º–µ—Ç–æ–¥—ã ({len(opencv_repos)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤)")
            
            ml_repos = [r for r in repos if any(keyword in r['description'].lower() 
                       for keyword in ['machine learning', 'deep learning', 'neural'])]
            if ml_repos:
                print(f"3. üß† –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å ML –ø–æ–¥—Ö–æ–¥—ã ({len(ml_repos)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤)")
            
            automation_repos = [r for r in repos if any(keyword in r['description'].lower() 
                               for keyword in ['selenium', 'playwright', 'automation'])]
            if automation_repos:
                print(f"4. ü§ñ –ò–∑—É—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ({len(automation_repos)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤)")
            
            print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {saved_file}")
            
        else:
            print("‚ùå –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É.")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏: {e}")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É")
        print("üí° –î–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ GITHUB_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è")
import os
import json
import asyncio
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Union

# –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–º–ø–æ—Ä—Ç—ã
from agent import UIAnalysisAgent
from constants import MOBILE_GAMING_UI_TAXONOMY, ALL_UI_TAGS

# –ù–æ–≤—ã–µ –≥–∏–±—Ä–∏–¥–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã
try:
    from hybrid_vision_agent import HybridUIVisionAgent
    HYBRID_AVAILABLE = True
except ImportError:
    HYBRID_AVAILABLE = False
    logging.warning("–ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–≥–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

class EnhancedUIAnalysisAgent(UIAnalysisAgent):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ AI Vision –∞–Ω–∞–ª–∏–∑–∞"""
    
    def __init__(self, credentials=None, anthropic_api_key=None, enable_hybrid=True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
        
        Args:
            credentials: Google OAuth2 credentials
            anthropic_api_key: API –∫–ª—é—á –¥–ª—è Claude Vision
            enable_hybrid: –í–∫–ª—é—á–∏—Ç—å –≥–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        """
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
        super().__init__(credentials)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        self.hybrid_agent = None
        self.hybrid_enabled = False
        
        if enable_hybrid and HYBRID_AVAILABLE:
            try:
                self.hybrid_agent = HybridUIVisionAgent(
                    anthropic_api_key=anthropic_api_key,
                    enable_phi=True,
                    enable_claude=bool(anthropic_api_key)
                )
                self.hybrid_enabled = True
                logging.info("‚úÖ –ì–∏–±—Ä–∏–¥–Ω—ã–π AI Vision –∞–≥–µ–Ω—Ç –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞: {str(e)}")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
    
    def get_analysis_capabilities(self) -> Dict[str, bool]:
        """–ü–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞"""
        capabilities = {
            "google_vision": bool(self.client),
            "hybrid_vision": self.hybrid_enabled,
            "phi_vision": False,
            "claude_vision": False
        }
        
        if self.hybrid_agent:
            available_services = self.hybrid_agent.get_available_services()
            capabilities["phi_vision"] = "phi" in available_services
            capabilities["claude_vision"] = "claude" in available_services
        
        return capabilities
    
    async def analyze_screenshot_enhanced(self, image_path: str, analysis_method: str = "auto") -> Dict:
        """
        –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤
        
        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            analysis_method: –ú–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ ('auto', 'google_only', 'hybrid', 'phi', 'claude')
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        image_path = Path(image_path)
        if not image_path.exists():
            raise FileNotFoundError(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {image_path}")
        
        logging.info(f"üéØ –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑: {image_path.name}")
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "image_path": str(image_path),
            "analysis_method": analysis_method,
            "capabilities": self.get_analysis_capabilities()
        }
        
        # –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ –∞–Ω–∞–ª–∏–∑–∞
        if analysis_method == "auto":
            analysis_method = self._choose_optimal_method()
        
        # Google Vision –∞–Ω–∞–ª–∏–∑ (–±–∞–∑–æ–≤—ã–π)
        if analysis_method in ["auto", "google_only", "hybrid"] and self.client:
            logging.info("üîÑ Google Vision –∞–Ω–∞–ª–∏–∑...")
            try:
                google_results = self.analyze_image(str(image_path))
                results["google_vision"] = google_results
                logging.info(f"‚úÖ Google Vision: {google_results['statistics']}")
            except Exception as e:
                logging.error(f"‚ùå Google Vision –æ—à–∏–±–∫–∞: {str(e)}")
                results["google_vision_error"] = str(e)
        
        # –ì–∏–±—Ä–∏–¥–Ω—ã–π AI Vision –∞–Ω–∞–ª–∏–∑
        if analysis_method in ["hybrid", "phi", "claude"] and self.hybrid_enabled:
            logging.info("üîÑ –ì–∏–±—Ä–∏–¥–Ω—ã–π AI Vision –∞–Ω–∞–ª–∏–∑...")
            try:
                # –í—ã–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                if analysis_method == "hybrid":
                    strategy = "hybrid"
                elif analysis_method == "phi":
                    strategy = "phi"
                elif analysis_method == "claude":
                    strategy = "claude"
                else:
                    strategy = "auto"
                
                hybrid_results = await self.hybrid_agent.smart_ui_analysis(
                    str(image_path), strategy
                )
                results["hybrid_vision"] = hybrid_results
                logging.info(f"‚úÖ –ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {hybrid_results.get('method_used', 'unknown')}")
            except Exception as e:
                logging.error(f"‚ùå –ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–∫–∞: {str(e)}")
                results["hybrid_vision_error"] = str(e)
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results["combined_analysis"] = self._combine_all_results(results)
        results["confidence_score"] = self._calculate_overall_confidence(results)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –æ–±—É—á–∞—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç
        self._save_enhanced_learning_data(results)
        
        logging.info(f"üéâ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. Confidence: {results['confidence_score']:.2f}")
        return results
    
    def _choose_optimal_method(self) -> str:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        capabilities = self.get_analysis_capabilities()
        
        if capabilities["hybrid_vision"]:
            return "hybrid"
        elif capabilities["claude_vision"]:
            return "claude"
        elif capabilities["phi_vision"]:
            return "phi"
        elif capabilities["google_vision"]:
            return "google_only"
        else:
            raise Exception("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞")
    
    def _combine_all_results(self, results: Dict) -> Dict:
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—Å–µ—Ö –∞–Ω–∞–ª–∏–∑–æ–≤"""
        combined = {
            "summary": {},
            "ui_elements_consensus": [],
            "text_analysis": {},
            "recommendations": []
        }
        
        # –ê–Ω–∞–ª–∏–∑ Google Vision —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if "google_vision" in results:
            gv = results["google_vision"]
            combined["summary"]["google_objects"] = gv.get("statistics", {}).get("objects_count", 0)
            combined["summary"]["google_texts"] = gv.get("statistics", {}).get("texts_count", 0)
            combined["text_analysis"]["google_extracted"] = len(gv.get("texts", []))
        
        # –ê–Ω–∞–ª–∏–∑ –≥–∏–±—Ä–∏–¥–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if "hybrid_vision" in results:
            hv = results["hybrid_vision"]
            combined["summary"]["hybrid_method"] = hv.get("method_used", "unknown")
            combined["summary"]["hybrid_confidence"] = hv.get("confidence_score", 0)
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
            if "phi_analysis" in hv and "claude_analysis" in hv:
                combined["recommendations"].append("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å Phi + Claude –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏")
            elif "claude_analysis" in hv:
                combined["recommendations"].append("Claude Vision –¥–∞–ª –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ UI —Å—Ç—Ä—É–∫—Ç—É—Ä—ã")
            elif "phi_analysis" in hv:
                combined["recommendations"].append("Phi Vision –æ–±–µ—Å–ø–µ—á–∏–ª –±—ã—Å—Ç—Ä—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
        
        return combined
    
    def _calculate_overall_confidence(self, results: Dict) -> float:
        """–†–∞—Å—á–µ—Ç –æ–±—â–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö"""
        confidence_factors = []
        
        # Google Vision factor
        if "google_vision" in results:
            gv_stats = results["google_vision"].get("statistics", {})
            if gv_stats.get("objects_count", 0) > 0 or gv_stats.get("texts_count", 0) > 0:
                confidence_factors.append(0.7)
        
        # Hybrid Vision factor
        if "hybrid_vision" in results:
            hv_confidence = results["hybrid_vision"].get("confidence_score", 0)
            confidence_factors.append(hv_confidence)
        
        # –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å –±–æ–Ω—É—Å–æ–º –∑–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        if confidence_factors:
            base_confidence = sum(confidence_factors) / len(confidence_factors)
            # –ë–æ–Ω—É—Å –∑–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            multiple_sources_bonus = 0.1 if len(confidence_factors) > 1 else 0
            return min(base_confidence + multiple_sources_bonus, 0.99)
        else:
            return 0.3
    
    def _save_enhanced_learning_data(self, results: Dict):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        enhanced_dir = Path("learning_data") / "enhanced"
        enhanced_dir.mkdir(parents=True, exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        full_analysis_path = enhanced_dir / f"enhanced_analysis_{timestamp}.json"
        with open(full_analysis_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        summary_path = enhanced_dir / f"summary_{timestamp}.json"
        summary_data = {
            "timestamp": results["timestamp"],
            "image_path": results["image_path"],
            "method": results["analysis_method"],
            "confidence": results["confidence_score"],
            "capabilities_used": results["capabilities"],
            "summary": results["combined_analysis"]["summary"]
        }
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, ensure_ascii=False, indent=2)
        
        logging.info(f"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {full_analysis_path.name}")
    
    async def batch_analyze_screenshots(self, 
                                       image_directory: str, 
                                       pattern: str = "*.png",
                                       max_files: int = None,
                                       analysis_method: str = "auto") -> List[Dict]:
        """
        –ú–∞—Å—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
        
        Args:
            image_directory: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
            pattern: –ü–∞—Ç—Ç–µ—Ä–Ω —Ñ–∞–π–ª–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "*.png", "*.jpg")
            max_files: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            analysis_method: –ú–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        """
        image_dir = Path(image_directory)
        if not image_dir.exists():
            raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {image_dir}")
        
        # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        image_files = list(image_dir.glob(pattern))
        if max_files:
            image_files = image_files[:max_files]
        
        if not image_files:
            logging.warning(f"–§–∞–π–ª—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {image_dir} —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º {pattern}")
            return []
        
        logging.info(f"üöÄ –ù–∞—á–∏–Ω–∞—é –º–∞—Å—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ {len(image_files)} —Ñ–∞–π–ª–æ–≤...")
        
        results = []
        for i, image_file in enumerate(image_files):
            logging.info(f"üì∏ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é {i+1}/{len(image_files)}: {image_file.name}")
            
            try:
                result = await self.analyze_screenshot_enhanced(
                    str(image_file), 
                    analysis_method
                )
                results.append(result)
                
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–ª—è API rate limiting
                if i % 5 == 0 and i > 0:
                    await asyncio.sleep(1)
                    
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {image_file.name}: {str(e)}")
                results.append({
                    "timestamp": datetime.now().isoformat(),
                    "image_path": str(image_file),
                    "error": str(e)
                })
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–∞—Å—Å–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        batch_results_path = self._save_batch_results(results)
        logging.info(f"üéâ –ú–∞—Å—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {batch_results_path}")
        
        return results
    
    def _save_batch_results(self, results: List[Dict]) -> Path:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–∞—Å—Å–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        batch_dir = Path("learning_data") / "batch_analysis"
        batch_dir.mkdir(parents=True, exist_ok=True)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        successful = [r for r in results if "error" not in r]
        failed = [r for r in results if "error" in r]
        
        batch_summary = {
            "timestamp": datetime.now().isoformat(),
            "total_files": len(results),
            "successful": len(successful),
            "failed": len(failed),
            "success_rate": len(successful) / len(results) if results else 0,
            "average_confidence": sum(r.get("confidence_score", 0) for r in successful) / len(successful) if successful else 0,
            "failed_files": [r["image_path"] for r in failed]
        }
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        full_results_path = batch_dir / f"batch_full_{timestamp}.json"
        with open(full_results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏
        summary_path = batch_dir / f"batch_summary_{timestamp}.json"
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(batch_summary, f, ensure_ascii=False, indent=2)
        
        logging.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {batch_summary['successful']}/{batch_summary['total_files']} —É—Å–ø–µ—à–Ω–æ")
        
        return full_results_path
    
    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        if self.hybrid_agent:
            self.hybrid_agent.cleanup()
        logging.info("üßπ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç –æ—á–∏—â–µ–Ω")
